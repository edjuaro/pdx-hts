{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNASeq workflow for PDX-HTS paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the analyses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:26.320667Z",
     "start_time": "2018-12-14T17:42:26.297124Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "from common_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:27.174352Z",
     "start_time": "2018-12-14T17:42:27.161086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pdx-hts/Notebooks/data/preprocessed/exp/pdx_affy_exp.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREPROC_PDX_AFFY_EXP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:29.302511Z",
     "start_time": "2018-12-14T17:42:29.297767Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pdx_affy = pd.read_csv(PREPROC_PDX_AFFY_EXP_FILE, index_col=0)\n",
    "#pdx_affy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:30.065653Z",
     "start_time": "2018-12-14T17:42:30.046750Z"
    },
    "genepattern": {
     "name": "Login",
     "server": "https://genepattern.broadinstitute.org/gp",
     "type": "auth"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdc9677b52a4b92b8ba8eaf197c82b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GPAuthWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Requires GenePattern Notebook: pip install genepattern-notebook\n",
    "import gp\n",
    "import genepattern\n",
    "\n",
    "# Username and password removed for security reasons.\n",
    "genepattern.display(genepattern.session.register(\"https://genepattern.broadinstitute.org/gp\", \"\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select parameters before running the rest of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3 style=\"margin-top: 0;\"> Instructions <i class=\"fa fa-info-circle\"></i></h3>\n",
    "Select parameters before running the rest of the notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:44:33.956193Z",
     "start_time": "2018-12-14T17:44:33.394147Z"
    },
    "nbtools": {
     "description": "",
     "name": "read_user_input",
     "param_values": {
      "DNA_Nexus": "false",
      "case_id": "PDX1",
      "control": "original",
      "custom_control_expression": "None",
      "dna_nexus_bool": "false",
      "is_medullo": "false",
      "output_var": "setup",
      "patient_dir": "PDX1_dir"
     },
     "show_code": false,
     "type": "uibuilder"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada4670bdcec429da0a36c83d98f2220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "UIBuilder(function_import='read_user_input', name='read_user_input', params=[{'name': 'case_id', 'label': 'casâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from companion_script import *\n",
    "# # Select case\n",
    "# case_id = 'case17'\n",
    "# # This patient directory should match the directory name on DNANexus.\n",
    "# patient_dir = '18-10716_tumor-normal'\n",
    "# is_medullo = True # set False if it is another kind of brain tumor\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import readline # required for rpy2 extension\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "\n",
    "def rmagic_warning(\n",
    "    message,\n",
    "    category = rpy2.rinterface.RRuntimeWarning,\n",
    "    filename = '',\n",
    "    lineno = -1,\n",
    "    file=None,\n",
    "    line=None):\n",
    "    print(message)\n",
    "default_showwarning = warnings.showwarning\n",
    "\n",
    "\n",
    "@genepattern.build_ui(parameters={\n",
    "    \"output_var\": {\n",
    "        \"default\": \"setup\",\n",
    "        \"hide\": False,\n",
    "    },\n",
    "    \"case_id\": {\"type\": \"text\",\n",
    "                \"description\": \"The name of the case, e.g., 'PDX1'\",\n",
    "               \"default\":\"PDX1\"},\n",
    "    \"patient_dir\": {\"type\": \"text\",\n",
    "                    \"description\": 'For DNA Nexus downloads only. The name of the \"patient\" directory, e.g. \"18-10716_tumor-normal\" (quotes are required)',\n",
    "                    \"default\":\"PDX1_dir\"},\n",
    "    \"dna_nexus_bool\": {\"type\": \"bool\",\n",
    "                   \"description\": \"Whether or not this sample has been classified as medulloblastoma\",\n",
    "                  \"default\":False},\n",
    "    \"is_medullo\": {\"type\": \"bool\",\n",
    "                   \"description\": \"Whether or not this sample has been classified as medulloblastoma\",},\n",
    "    \"control\": {\"type\": \"choice\",\n",
    "                \"description\": \"Whether or not to use a custom control\",\n",
    "                \"choices\": {\n",
    "                    \"original\": \"original\",\n",
    "                    \"custom\": \"custom\",\n",
    "                            }\n",
    "               },\n",
    "    \"custom_control_expression\": {\"type\": \"file\",\n",
    "                           \"kinds\": [\"gct\"],\n",
    "                           \"description\": \"The file (or path to the GCT file) which contains the gene expression of the custom control.\",\n",
    "                           \"default\":None},\n",
    "})\n",
    "def read_user_input(case_id, patient_dir, dna_nexus_bool=False, is_medullo=False, control='original',custom_control_expression=None):\n",
    "    # Select control for DiSCoVER and Connectivity Map\n",
    "    # Generally, if the tumor is a medulloblastoma, we use `cerebellar_stem` (comment the `neural_stem` line).\n",
    "    # And if it is any other kind of brain tumor, we use `neural_stem`.\n",
    "    if control == 'original':\n",
    "        expression_control = 'cerebellar_stem' if is_medullo else 'neural_stem'\n",
    "    elif control == 'custom':\n",
    "        expression_control = 'custom_control'\n",
    "    else:\n",
    "        print('Unexpected value for variable named control, value:', control)\n",
    "        \n",
    "    if (len(custom_control_expression) is not 0) and (control is not 'custom'):\n",
    "        print(\"Reminder: if you want to use a custom control expresion, you must set control to 'custom'\")\n",
    "\n",
    "    base_dir = os.getcwd()\n",
    "    utilities_dir = '/build'\n",
    "    patients_dir = os.path.join(base_dir, 'patients')\n",
    "    if not dna_nexus_bool:\n",
    "        log('Setting patient_dir = case_id')\n",
    "        patient_dir = case_id\n",
    "        \n",
    "    in_dir = os.path.join(patients_dir, patient_dir)\n",
    "    \n",
    "    out_dir = in_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "#     out['base_dir'] = base_dir\n",
    "#     out['utilities_dir'] = utilities_dir\n",
    "#     out['patients_dir'] = patients_dir\n",
    "#     \n",
    "\n",
    "    platform = sys.platform\n",
    "    if platform.startswith('linux'):\n",
    "        os_string = 'linux'\n",
    "    elif platform == 'darwin':\n",
    "        os_string = 'mac'\n",
    "    else:\n",
    "        raise ValueError('Platform \"{}\" not supported'.format(platform))\n",
    "\n",
    "    # RNASeq quantification\n",
    "    kallisto_dir = '/build/kallisto'\n",
    "    kallisto_path = os.path.join(kallisto_dir, 'kallisto_{}-v0.44.0/kallisto'.format(os_string))\n",
    "    transcriptome_index_path = os.path.join(kallisto_dir, 'GRCh38.ensembl.transcriptome.idx')\n",
    "    local_fastqs_dir = os.path.join(in_dir, 'fastqs')\n",
    "    os.makedirs(local_fastqs_dir, exist_ok=True)\n",
    "    patient_gexp_file = os.path.join(out_dir, 'gene_abundance.sleuth.csv')\n",
    "\n",
    "    # Medulloblastoma classification\n",
    "#     from sklearn.ensemble import RandomForestClassifier\n",
    "#     from tumor_classification.medulloblastoma import classify_cavalli, classify_cho, classify_northcott\n",
    "    medullo_classify_out_dir = os.path.join(out_dir, 'medulloblastoma_classification')\n",
    "    if not os.path.exists(medullo_classify_out_dir):\n",
    "        os.mkdir(medullo_classify_out_dir)\n",
    "    cavalli_subgroup_file = os.path.join(medullo_classify_out_dir, 'cavalli_subgroups.csv')\n",
    "    cavalli_subgroup_direct_file = os.path.join(medullo_classify_out_dir, 'cavalli_subgroups_direct.csv')\n",
    "    cavalli_subtype_file = os.path.join(medullo_classify_out_dir, 'cavalli_subtypes.csv')\n",
    "    cho_subtype_file = os.path.join(medullo_classify_out_dir, 'cho_subtypes.csv')\n",
    "    cho_subgroup_file = os.path.join(medullo_classify_out_dir, 'cho_subgroups.csv')\n",
    "    northcott_subgroup_file = os.path.join(medullo_classify_out_dir, 'northcott_subgroups.csv')\n",
    "\n",
    "    drug_suggestion_out_dir = os.path.join(out_dir, 'drug_suggestions')\n",
    "    os.makedirs(drug_suggestion_out_dir, exist_ok=True)\n",
    "\n",
    "    # DiSCoVER\n",
    "    discover_out_dir = os.path.join(drug_suggestion_out_dir, 'discover/{}'.format(expression_control))\n",
    "    os.makedirs(discover_out_dir, exist_ok=True)\n",
    "    discover_heatmap_file = os.path.join(discover_out_dir, 'ctrp.png')\n",
    "    full_discover_results_file = os.path.join(discover_out_dir, 'discover.all.csv')\n",
    "    rdrugs_discover_file = os.path.join(discover_out_dir, '{}.discover.{}.reasonable.annotated.csv'.format(case_id, expression_control))\n",
    "\n",
    "    # Connectivity Map\n",
    "    cmap_out_dir = os.path.join(drug_suggestion_out_dir, 'cmap/{}'.format(expression_control))\n",
    "    os.makedirs(cmap_out_dir, exist_ok=True)\n",
    "    cmap_all_ranked_drugs_file = os.path.join(cmap_out_dir, '{}.cmap.{}.all.csv'.format(case_id, expression_control))\n",
    "    cmap_reasonable_ranked_drugs_file = os.path.join(cmap_out_dir, '{}.cmap.{}.reasonable.annotated.csv'.format(case_id, expression_control))\n",
    "    \n",
    "    # Powerpoint for MTB\n",
    "#     from slides import make_medullo_classification_slide, make_discover_workflow_slide, make_exp_drug_ranking_results_slide, make_intersection_slide\n",
    "    mtb_ppt_file = os.path.join(out_dir, '{}.mtb_slides.pptx'.format(case_id))\n",
    "\n",
    "    # DNANexus\n",
    "    dx_source_path = os.path.join(utilities_dir, 'dx-toolkit/environment')\n",
    "    dnanexus_project = 'UW_UCSD_RNAseq_collaboration_share'\n",
    "    # Replace the contents of this file with your own DNANexus token.\n",
    "    dnanexus_token_file = os.path.join(base_dir, 'dnanexus_token.txt')\n",
    "    # To use the dx command, we must update some environment variables. \n",
    "    # From the command line, this is done with source dx-toolkit/environment, \n",
    "    # but from Python we have to use a workaround, because normally any changes \n",
    "    # to environment variables done in a subprocess are not reflected in the \n",
    "    # parent process. The workaround runs the source command in a subprocess, \n",
    "    # fetches the environment variables from the subprocess and updates those \n",
    "    # of the parent process.\n",
    "#     from utils import source_and_update_env_vars\n",
    "    source_and_update_env_vars(dx_source_path)    \n",
    "    out = {\"case_id\": case_id,\n",
    "                 \"patient_dir\": patient_dir,\n",
    "                 \"is_medullo\": is_medullo}\n",
    "    out['dna_nexus_bool']=dna_nexus_bool\n",
    "    out['expression_control'] = expression_control\n",
    "    out['custom_control_expression'] = custom_control_expression\n",
    "    out['dnanexus_token_file'] = dnanexus_token_file\n",
    "    out['local_fastqs_dir'] = local_fastqs_dir\n",
    "    out['dnanexus_project'] = dnanexus_project\n",
    "    out['local_fastqs_dir'] = local_fastqs_dir\n",
    "    out['transcriptome_index_path'] = transcriptome_index_path\n",
    "    out['kallisto_path'] = kallisto_path\n",
    "    out['kallisto_dir'] = kallisto_dir\n",
    "    out['out_dir'] = out_dir\n",
    "    out['r_out_dir'] = out_dir.replace('\\\\',r'\\\\')\n",
    "    out['patient_gexp_file'] = patient_gexp_file\n",
    "    out['in_dir'] = in_dir\n",
    "    out['cavalli_subgroup_file'] = cavalli_subgroup_file\n",
    "    out['cavalli_subtype_file'] = cavalli_subtype_file\n",
    "    out['cavalli_subgroup_direct_file'] = cavalli_subgroup_direct_file\n",
    "    out['cho_subgroup_file'] = cho_subgroup_file\n",
    "    out['cho_subtype_file'] = cho_subtype_file\n",
    "    out['northcott_subgroup_file'] = northcott_subgroup_file\n",
    "    out['mtb_ppt_file'] = mtb_ppt_file\n",
    "    out['expression_control'] = expression_control\n",
    "    out['full_discover_results_file'] = full_discover_results_file\n",
    "    out['discover_out_dir'] = discover_out_dir\n",
    "    out['discover_heatmap_file'] = discover_heatmap_file\n",
    "    out['rdrugs_discover_file'] = rdrugs_discover_file\n",
    "    out['cmap_out_dir'] = cmap_out_dir\n",
    "    out['cmap_all_ranked_drugs_file'] = cmap_all_ranked_drugs_file\n",
    "    out['cmap_reasonable_ranked_drugs_file'] = cmap_reasonable_ranked_drugs_file\n",
    "    out['mtb_ppt_file'] = mtb_ppt_file\n",
    "    out['out_dir'] = os.path.join(patients_dir, case_id)\n",
    "\n",
    "    if not os.path.exists(out['out_dir']):\n",
    "        os.mkdir(out['out_dir'])\n",
    "    print('Setup done!')\n",
    "    pickle.dump(out, file=open(out['out_dir']+'_backup1_input.p','wb'))\n",
    "    return Bunch(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"well\">\n",
    "Running all cells below this point will execute all the analyses except for one: the Connectivity Map analysis at the end of the notebook, which requires two manual steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download RNAseq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:11.335422Z",
     "start_time": "2018-12-14T17:42:10.129Z"
    },
    "nbtools": {
     "description": "",
     "name": "download_and_preprocess_rnaseq",
     "param_values": {
      "input_expression_dir": "'/pdx-hts/Notebooks/data/preprocessed/exp/pdx_affy_exp.csv'",
      "output_var": "setup",
      "setup": "setup"
     },
     "show_code": true,
     "type": "uibuilder"
    }
   },
   "outputs": [],
   "source": [
    "@genepattern.build_ui(parameters={\n",
    "    \"setup\": {\"default\": \"setup\",\n",
    "              \"hide\": False,\n",
    "              \"description\": \"The variable which has the setup information\"},\n",
    "    \"output_var\": {\n",
    "        \"default\": \"setup\",\n",
    "        \"hide\": True,\n",
    "    },\n",
    "})\n",
    "def download_and_preprocess_rnaseq(setup, input_expression_dir = None):\n",
    "    setup.input_expression_dir = input_expression_dir\n",
    "    if setup.dna_nexus_bool:\n",
    "        if input_expression_dir is not None:\n",
    "            log(f\"input_expression_dir has a value ({setup.input_expression_dir}), and it will be ignored!\")\n",
    "        log('About to download fastqfiles from DNA Nexus. This may take a while.')\n",
    "        with open(setup.dnanexus_token_file, 'r') as f:\n",
    "            dnanexus_token = f.readline().strip()\n",
    "        login_command = 'dx login --token {} --noprojects; dx select {}'.format(dnanexus_token, setup.dnanexus_project)\n",
    "        # subprocess.check_output('ls', shell=True).decode('utf-8').strip()\n",
    "        subprocess.check_output(login_command, shell=True).decode('utf-8').strip()\n",
    "\n",
    "        find_fastq_command = 'dx find data --name \"*.fastq.gz\" --path {}:{}'.format(setup.dnanexus_project, setup.patient_dir)\n",
    "        find_fastq_return_lines = subprocess.check_output(find_fastq_command, shell=True).decode().strip().split('\\n')\n",
    "        re_string = '.*(/{}/.*\\.fastq.gz) .*'.format(setup.patient_dir)\n",
    "        fastq_path_re = re.compile(re_string)\n",
    "        remote_fastq_paths = []\n",
    "        local_fastq_subdirs = []\n",
    "\n",
    "        for line in find_fastq_return_lines:\n",
    "            search = fastq_path_re.search(line)\n",
    "            remote_fastq_path = search.group(1)\n",
    "            remote_fastq_paths.append(remote_fastq_path)\n",
    "            fastq_subdir_path = os.path.dirname(remote_fastq_path)\n",
    "            fastq_subdir = os.path.basename(fastq_subdir_path)\n",
    "            local_fastq_subdir = os.path.join(setup.local_fastqs_dir, fastq_subdir)\n",
    "            os.makedirs(local_fastq_subdir, exist_ok=True)\n",
    "            local_fastq_subdirs.append(local_fastq_subdir)\n",
    "\n",
    "        for remote_fastq_path, local_fastq_subdir in zip(remote_fastq_paths, local_fastq_subdirs):\n",
    "            download_command = 'dx download \"{}\" -o \"{}\"'.format(remote_fastq_path, local_fastq_subdir)\n",
    "            print('\\t'+download_command)\n",
    "            try:\n",
    "                a=subprocess.check_output(download_command, shell=True)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print('\\tEncountered a dx error, this likely means you already have the file indicated above.')\n",
    "                print('\\tContinuing...\\n')\n",
    "                continue\n",
    "        log('Done downloading the fastq files.')\n",
    "        log('Preprocessing RNASeq data now:')\n",
    "        log('Using kallisto to compute transcript abundance.')\n",
    "        preprocess_rna_seq(setup)\n",
    "        log('Done with tanscript abundance.')\n",
    "        log('Using sleuth to aggregate transcript abundance into gene abbundance.')\n",
    "        run_sleuth(setup)\n",
    "        patient_exp = pd.read_csv(setup.patient_gexp_file, index_col=0).T\n",
    "        patient_exp.index = [setup.case_id]\n",
    "        setup.patient_exp = patient_exp\n",
    "        patient_exp.to_csv(setup.patient_gexp_file)\n",
    "        log('Habemus Genus Expressium *release the white smoke*')\n",
    "    else:\n",
    "        log(f'Checking if local file ({setup.input_expression_dir}) exist.')\n",
    "        if os.path.isfile(setup.input_expression_dir):\n",
    "            df = pd.read_csv(setup.input_expression_dir, index_col=0)\n",
    "            setup.expression_input = df\n",
    "            log(\"This file containes the expression of the PDXs. Printing dataframe's info:\")\n",
    "            log(setup.expression_input.info())\n",
    "        else:\n",
    "            log('File could not be located please check and run again.')\n",
    "        patient_exp = df\n",
    "        setup.patient_exp = patient_exp\n",
    "        patient_exp.to_csv(setup.patient_gexp_file)\n",
    "        log(f'File {setup.patient_gexp_file} saved successfully')\n",
    "    \n",
    "    pickle.dump(setup, file=open(setup.out_dir+'_backup2_download.p','wb'))\n",
    "    log('Done preprocessing!')\n",
    "    return setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the tumor by medulloblastoma subgroup and subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:11.336880Z",
     "start_time": "2018-12-14T17:42:10.133Z"
    },
    "nbtools": {
     "description": "This function classifies a medulloblastoma sample into a subgroup. Non-medulloblastoma samples are ignored.",
     "name": "classify_sample",
     "param_values": {
      "output_var": "setup",
      "setup": "setup"
     },
     "show_code": false,
     "type": "uibuilder"
    }
   },
   "outputs": [],
   "source": [
    "@genepattern.build_ui(\n",
    "    description=\"This function classifies a medulloblastoma sample into a subgroup. Non-medulloblastoma samples are ignored.\",\n",
    "    parameters={\n",
    "    \"setup\": {\"default\": \"setup\",\n",
    "              \"hide\": False,\n",
    "              \"description\": \"The variable which has the setup information\"},\n",
    "    \"output_var\": {\n",
    "        \"default\": \"setup\",\n",
    "        \"hide\": True,\n",
    "    },\n",
    "})\n",
    "def classify_sample(setup):\n",
    "    # We have three datasets we can use to classify based on expression:\n",
    "    # - [Cavalli et al. 2017](http://www.sciencedirect.com/science/article/pii/S1535610817302015) cohort. This cohort includes 763 tumors, and was used to define 12 finer-grained subtypes nested in the 4 subgroups. Both expression and methylation data are available.\n",
    "\n",
    "    # - [Cho et al. 2011](http://www.mesirovlab.org/medulloblastoma/cho/) cohort. This paper identified two subtypes within G3 and two within G4, for a total of 6. It contains 194 tumors.\n",
    "\n",
    "    # - [Northcott et al. 2017](http://www.nature.com/nature/journal/v547/n7663/full/nature22973.html) expression data (shared by Sebastian). The labels we have for this data are of the 4 basic subgroups only. There are 223 tumors.\n",
    "\n",
    "    # When finer-grained subtypes are known, we perform the finer-grained classification first and also collapse the subtypes to the 4 basic subgroups, so as to report both subtype and subgroup probabilities. Classification is done using random forests.\n",
    "\n",
    "    # Since the patient data are from the same platform and contain the same features each time, we can use pre-fit models to classify them. The classification methods also have a fallback in case the data looks different.\n",
    "\n",
    "    # The tumor board is arranging for methylation data to be obtained from patient samples as well, since it seems it may be more informative than expression. Methylation data would also allow comparison to a large and variety collection of brain tumors, currently available through a DKFZ [web portal](https://www.molecularneuropathology.org/mnp).\n",
    "\n",
    "    if setup.is_medullo:\n",
    "        # Read in patient's gene-level RNASeq TPM data\n",
    "        patient_exp = pd.read_csv(setup.patient_gexp_file, index_col=0)\n",
    "\n",
    "        cavalli_subgroups, cavalli_subtypes = classify_cavalli(patient_exp)\n",
    "        cavalli_subgroups.to_csv(setup.cavalli_subgroup_file)\n",
    "        cavalli_subtypes.to_csv(setup.cavalli_subtype_file)\n",
    "\n",
    "        cho_subgroups, cho_subtypes = classify_cho(patient_exp)\n",
    "        cho_subtypes.to_csv(setup.cho_subtype_file)\n",
    "        cho_subgroups.to_csv(setup.cho_subgroup_file)\n",
    "\n",
    "        northcott_subgroups = classify_northcott(patient_exp)\n",
    "        northcott_subgroups.to_csv(setup.northcott_subgroup_file)\n",
    "\n",
    "        make_medullo_classification_slide(setup.mtb_ppt_file,\n",
    "                                          setup.cavalli_subgroup_file,\n",
    "                                          setup.cavalli_subtype_file,\n",
    "                                          setup.cho_subgroup_file,\n",
    "                                          setup.cho_subtype_file,\n",
    "                                          setup.northcott_subgroup_file)\n",
    "    pickle.dump(setup, file=open(setup.out_dir+'_backup3_classify.p','wb'))\n",
    "    return setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest drugs based on RNAseq data (DiSCoVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = pickle.load(file=open(setup.case_id+'_DISCoVER_pre_modifications.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:31:54.017634Z",
     "start_time": "2018-12-14T17:31:53.874286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modified from https://gist.github.com/woemler/8601450\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import re\n",
    "\n",
    "\n",
    "def fetch_page_soup(url):\n",
    "    \"\"\" Fetches page data from a URL and returns a parsed BeautifulSoup object \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = urllib2.urlopen(url)\n",
    "        soup = BeautifulSoup(response.read())\n",
    "    finally:\n",
    "        if response:\n",
    "            response.close()\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def find_cosmic_cell_line(cosmic_id):\n",
    "    \"\"\" Returns a COSMIC cell line's annotation, given a COSMIC ID. \"\"\"\n",
    "\n",
    "    url = r'http://cancer.sanger.ac.uk/cosmic/sample/overview?id=%s'%(str(cosmic_id))\n",
    "    soup = fetch_page_soup(url)\n",
    "#     print(soup)\n",
    "#     soup = soup.find(\"div\", id=\"section-list\").find(\"div\", {\"class\":re.compile(\"w75\")})\n",
    "    soup = soup.find(\"div\", id=\"section-list\")\n",
    "#     print(soup)\n",
    "    metadata = {}\n",
    "    metadata[\"name\"] = soup.find(text=\"Sample name\").findNext(\"dd\").find(\"a\").string.replace('\\n','').replace(' ','')\n",
    "    metadata[\"simplified_name\"] = metadata[\"name\"].replace('_','').replace('-','')\n",
    "    metadata[\"type\"] = soup.find(text=\"Tumour location\").findNext(\"dd\").contents[0].string.replace('\\n','').replace('  ','')\n",
    "\n",
    "#     metadata = {}\n",
    "\n",
    "#     #The sample metadata is stored in the \"overview\" tab\n",
    "#     if soup.find(\"div\", id=\"overview\"):\n",
    "#         soup = soup.find(\"div\", id=\"overview\").find(\"div\", {\"class\":re.compile(\"w75\")})\n",
    "\n",
    "#         #Zip the metadata up into a dictionary\n",
    "#         metadata = dict(zip([x.string for x in soup.findAll(\"dt\")], [x.string for x in soup.findAll(\"dd\")]))\n",
    "\n",
    "#         #The sample name will not properly parse this way, so we have to pluck it out separately.\n",
    "#         metadata[\"Sample name\"] = soup.find(text=\"Sample name\").findNext(\"dd\").find(\"a\").string\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:31:59.490119Z",
     "start_time": "2018-12-14T17:31:56.707683Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/conda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'SK-MEL-31',\n",
       " 'simplified_name': 'SKMEL31',\n",
       " 'type': 'Skin (Malignant melanoma)'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_cosmic_cell_line('909727')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:42:11.338324Z",
     "start_time": "2018-12-14T17:42:10.156Z"
    },
    "nbtools": {
     "description": "Run DiSCoVER on the provided sample and control.",
     "name": "run_discover",
     "param_values": {
      "output_var": "setup",
      "setup": "setup"
     },
     "show_code": false,
     "type": "uibuilder"
    }
   },
   "outputs": [],
   "source": [
    "@genepattern.build_ui(\n",
    "  description=\"Run DiSCoVER on the provided sample and control.\",\n",
    "  parameters={\n",
    "    \"setup\": {\"default\": \"setup\",\n",
    "              \"hide\": False,\n",
    "              \"description\": \"The variable which has the setup information\"},\n",
    "    \"output_var\": {\n",
    "        \"default\": \"setup\",\n",
    "        \"hide\": True,\n",
    "    },\n",
    "})\n",
    "def run_discover(setup):\n",
    "    from rpy2.robjects import numpy2ri\n",
    "    numpy2ri.activate()\n",
    "    from discover_temp import discover_from_expression, plot_discover_from_expression\n",
    "    from drug_suggestion.expression.controls import load_control_exp\n",
    "    patient_exp = pd.read_csv(setup.patient_gexp_file, index_col=0)\n",
    "    control_exp = load_control_exp(setup.expression_control)\n",
    "    log(\"About to perform DiSCoVER.\")\n",
    "    discover_results = discover_from_expression(exp=patient_exp, \n",
    "                                                control_exp=control_exp, \n",
    "                                                verbose=True)\n",
    "    # move some files created by DiSCoVER\n",
    "    for cl_name in ['ccle','ctrp','gdsc']:\n",
    "        os.rename(f\"COSMIC_cell_lines_IDs_and_types_{cl_name}.csv\", os.path.join(setup.out_dir, f\"COSMIC_cell_lines_IDs_and_types_{cl_name}.csv\"))\n",
    "    \n",
    "    log(\"DiSCoVER done!\")\n",
    "    numpy2ri.deactivate()\n",
    "    log('Saving results to file.')\n",
    "    # display(discover_results)\n",
    "    discover_results.T.sort_values(by=setup.case_id, ascending=False).to_csv(setup.full_discover_results_file)\n",
    "    log(\"Saving done!\")\n",
    "    log(\"Restricting to clinically relevant drugs.\")\n",
    "    #Not all drugs in CCLE, CTRP, and GDSC are realistic candidates for treatment. We compiled a list of medications that are FDA-approved or in late-stage clinical trials, and Dr. Wechsler-Reya curated it to include only those that are relevant for treating brain tumors. Here we limit the results to these drugs and add Dr. Wechsler-Reya's mechanism-of-action annotations. To enable comparison of drug lists, drugs from the different sources have been mapped to PubChem compound IDs (CIDs) using [PubChemPy](http://pubchempy.readthedocs.io/en/latest/).\n",
    "    from drug_suggestion.drug_annotation import subset_to_reasonable_drugs\n",
    "    from drug_suggestion.expression.discover import load_discover_drug_to_cids\n",
    "    disco2cid = load_discover_drug_to_cids()\n",
    "    reasonable_results = subset_to_reasonable_drugs(discover_results, \n",
    "                                                disco2cid, \n",
    "                                                out_prefix='discover.{}'.format(setup.expression_control), \n",
    "                                                out_dir=setup.discover_out_dir)\n",
    "    log('Done restricting to clinically relevant drugs!')\n",
    "    \n",
    "#     log('making a discover illustrative method')\n",
    "#     from drug_suggestion.expression.discover import plot_discover_from_expression\n",
    "#     plot_discover_from_expression(case_id, \n",
    "#                                   discover_results, \n",
    "#                                   exp=patient_exp,\n",
    "#                                   control_exp=control_exp,\n",
    "#                                   cl='ctrp',\n",
    "#                                   out_file=discover_heatmap_file)\n",
    "#     make_discover_workflow_slide(mtb_ppt_file, discover_heatmap_file)\n",
    "    log('Making the DiSCoVER powerpoint.')\n",
    "    rdrugs_discover = pd.read_csv(setup.rdrugs_discover_file, index_col=None)\n",
    "    df = split_discover_dataframe(df=rdrugs_discover)\n",
    "    df = rank_drugs_discover(df)\n",
    "#     df.head()\n",
    "    make_exp_drug_ranking_results_slide(setup.mtb_ppt_file, df.head(20), setup.expression_control, method='DiSCoVER')\n",
    "    log('Done making the DiSCoVER powerpoint slide!')\n",
    "    log('Savig the variables to a file.')\n",
    "    setup.discover_results = discover_results\n",
    "    setup.disco2cid = disco2cid\n",
    "    setup.control_exp = control_exp\n",
    "    setup.reasonable_results = reasonable_results\n",
    "    setup.df = df\n",
    "    pickle.dump(setup, file=open(setup.out_dir+'_backup4_DISCoVER.p','wb'))\n",
    "#     pickle.dump(setup, file=open(setup.case_id+'_DISCoVER.p','wb'))\n",
    "    log('Done savig the variables to a file!')\n",
    "    \n",
    "    log('Done with all the taks in this cell. Move along.')\n",
    "    return setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cl_name in ['ccle','ctrp','gdsc']:\n",
    "#     os.rename(f\"COSMIC_cell_lines_IDs_and_types_{cl_name}.csv\", os.path.join(setup.out_dir, f\"COSMIC_cell_lines_IDs_and_types_{cl_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cl_name in ['ccle','ctrp','gdsc']:\n",
    "# Loading the three ccle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(setup, file=open(setup.case_id+'_DISCoVER_pre_modifications.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.discover_results.T.sort_values(by=setup.case_id, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Select signature genes for Connectivity Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(setup, file=open(setup.case_id+'_DISCoVER.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:34:03.119910Z",
     "start_time": "2018-12-14T17:34:03.070546Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PDX1_DISCoVER.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6d8d8cd0c273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msetup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_DISCoVER.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PDX1_DISCoVER.p'"
     ]
    }
   ],
   "source": [
    "setup = pickle.load(file=open(setup.case_id+'_DISCoVER.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:47:23.658908Z",
     "start_time": "2018-12-14T17:47:23.303638Z"
    },
    "nbtools": {
     "description": "This function parses CMap's results.",
     "name": "make_cmap_slide",
     "param_values": {
      "output_var": "setup",
      "setup": "setup"
     },
     "show_code": true,
     "type": "uibuilder"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2728a94cb6cb40e4b85d50a4b264331f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "UIBuilder(description=\"This function parses CMap's results.\", function_import='make_cmap_slide', name='make_cmâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@genepattern.build_ui(\n",
    "  description=\"This function parses CMap's results.\",\n",
    "  parameters={\n",
    "    \"setup\": {\"default\": \"setup\",\n",
    "              \"hide\": False,\n",
    "              \"description\": \"The variable which has the setup information\"},\n",
    "    \"output_var\": {\n",
    "        \"default\": \"setup\",\n",
    "        \"hide\": True,\n",
    "    },\n",
    "})\n",
    "def make_cmap_slide(setup):\n",
    "    log('About to parse CMap results.')\n",
    "    patient_exp = pd.read_csv(setup.patient_gexp_file, index_col=0)\n",
    "    control_exp = load_control_exp(setup.expression_control)\n",
    "    cmap_genesets = make_cmap_genesets(patient_exp, control_exp)\n",
    "    write_cmap_genesets(cmap_genesets, setup.cmap_out_dir)\n",
    "\n",
    "    # must match path to downloaded .gct file\n",
    "    cmap_gct = os.path.join(setup.cmap_out_dir, 'cmap_result.gct')\n",
    "\n",
    "    if os.path.exists(cmap_gct):\n",
    "        cmap_ranked_drugs = read_cmap_gct(cmap_gct)\n",
    "        cmap_ranked_drugs.columns = [setup.case_id]\n",
    "        cmap_ranked_drugs.to_csv(setup.cmap_all_ranked_drugs_file)\n",
    "        cmap2cid = load_cmap_drug_to_cids()\n",
    "        cmap_reasonable = subset_to_reasonable_drugs(cmap_ranked_drugs.T, \n",
    "                                   cmap2cid,\n",
    "                                   out_prefix='cmap.{}'.format(setup.expression_control), \n",
    "                                   out_dir=setup.cmap_out_dir).sort_values(by=setup.case_id, ascending=False)\n",
    "        rdrugs_cmap = pd.read_csv(setup.cmap_reasonable_ranked_drugs_file, index_col=None)\n",
    "        make_exp_drug_ranking_results_slide(setup.mtb_ppt_file, rdrugs_cmap, setup.expression_control, method='CMap')\n",
    "        setup.rdrugs_cmap = rdrugs_cmap\n",
    "        pickle.dump(setup, file=open('patients/'+setup.patient_dir+'/drug_suggestions/'+setup.case_id+'_drug_recommendations.p','wb'))\n",
    "        log(\"done!\")\n",
    "    else:\n",
    "        log(f\"cmap_result.gct not found! (It should be present in the directiory {setup.cmap_out_dir}).\")\n",
    "        log(\"Try again if you'd like to see CMap results.\")\n",
    "        log(\"Hint, you may want to go here:\")\n",
    "        log(\"https://clue.io/l1000-query#individual\")\n",
    "    \n",
    "    pickle.dump(setup, file=open(setup.out_dir+'_backup5_CMap.p','wb'))\n",
    "    return setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiSCoVER \"supporting information\" or \"evidence\" means in how many of the three drug databases that drug is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T18:06:12.587809Z",
     "start_time": "2018-12-14T18:06:12.505739Z"
    },
    "nbtools": {
     "description": "This function merges the results of DiSCoVER and CMap.",
     "name": "merge_discover_and_cmap",
     "param_values": {
      "output_var": "setup",
      "setup": "setup"
     },
     "show_code": false,
     "type": "uibuilder"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f58712405a4ede9cf4dcc13bc729a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "UIBuilder(description='This function merges the results of DiSCoVER and CMap.', function_import='merge_discoveâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@genepattern.build_ui(\n",
    "  description=\"This function merges the results of DiSCoVER and CMap.\",\n",
    "  parameters={\n",
    "    \"setup\": {\"default\": \"setup\",\n",
    "              \"hide\": False,\n",
    "              \"description\": \"The variable which has the setup information\"},\n",
    "    \"output_var\": {\n",
    "        \"default\": \"setup\",\n",
    "        \"hide\": True,\n",
    "    },\n",
    "})\n",
    "def merge_discover_and_cmap(setup):\n",
    "    log('Merging results from DiSCoVER and CMap.')\n",
    "    combined_df = add_cmap_to_split_df(discover=setup.df,cmap=setup.rdrugs_cmap)\n",
    "    to_slide = rank_combined_df(combined_df)\n",
    "    make_intersection_slide(setup.mtb_ppt_file, to_slide, setup.expression_control, method='DiSCoVER âˆ© CMap')\n",
    "    \n",
    "    log(\"Done Merging results from DiSCoVER and CMap!\")\n",
    "    log(\"Saving combined_df and to_slide on setup variable\")\n",
    "    setup.combined_df = combined_df\n",
    "    setup.to_slide = to_slide\n",
    "    pickle.dump(setup, file=open('patients/'+setup.patient_dir+'/drug_suggestions/'+setup.case_id+'_drug_recommendations_merged.p','wb'))\n",
    "    pickle.dump(setup, file=open(setup.out_dir+'_backup6_merged.p','wb'))\n",
    "    log(\"Done done!\")\n",
    "    return setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.to_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
